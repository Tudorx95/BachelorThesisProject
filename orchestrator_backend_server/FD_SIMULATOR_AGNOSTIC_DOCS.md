# ðŸŽ¯ FD Simulator Agnostic - DocumentaÈ›ie CompletÄƒ

## ðŸ“‹ Overview

**fd_simulator_agnostic.py** este o versiune **complet agnosticÄƒ** a simulatorului FL care:
- âŒ **NU aplicÄƒ** nicio preprocesare hardcoded
- âŒ **NU impune** label_mode, color_mode sau alte setÄƒri
- âœ… **DELEGE** toatÄƒ logica de date cÄƒtre template
- âœ… **OFERÄ‚** control total utilizatorului

---

## ðŸ”„ Ce S-a Schimbat?

### ÃŽnainte (fd_simulatorV2.py) - âŒ OPINIONATED

```python
# Simulator IMPUNEA preprocesÄƒri hardcoded:

def _load_tensorflow_data(train_dir, test_dir, batch_size):
    # âŒ Hardcoded: label_mode='categorical'
    train_ds = tf.keras.utils.image_dataset_from_directory(
        train_dir,
        label_mode='categorical',  # â† IMPUS de simulator!
        color_mode='rgb',           # â† IMPUS de simulator!
        ...
    )
    
    # âŒ Hardcoded: normalizare default
    def normalize(image, label):
        return tf.cast(image, tf.float32) / 255.0, label
    train_ds = train_ds.map(normalize)  # â† IMPUSÄ‚ de simulator!
```

**Probleme**:
- Double one-hot encoding (simulator + template)
- Nu poÈ›i folosi sparse labels
- Nu poÈ›i customiza preprocesarea
- Nu poÈ›i folosi alte transformÄƒri

### DupÄƒ (fd_simulator_agnostic.py) - âœ… AGNOSTIC

```python
# Simulator DELEGE totul cÄƒtre template:

def load_data(data_path, framework, batch_size):
    # âœ… Priority 1: Template's complete custom loading
    if TEMPLATE_FUNCS.has_function('load_client_data'):
        return TEMPLATE_FUNCS.get_function('load_client_data')(
            str(data_path), batch_size
        )
    
    # âœ… Priority 2: Template's general loading
    elif TEMPLATE_FUNCS.has_function('load_train_test_data'):
        train_ds, test_ds = TEMPLATE_FUNCS.get_function('load_train_test_data')()
        
        if TEMPLATE_FUNCS.has_function('preprocess_loaded_data'):
            train_ds, test_ds = TEMPLATE_FUNCS.get_function('preprocess_loaded_data')(
                train_ds, test_ds
            )
        return train_ds, test_ds
    
    # âœ… Error: template TREBUIE sÄƒ implementeze data loading
    else:
        raise SimulationError("Template must implement data loading!")
```

**Beneficii**:
- Zero preprocesÄƒri hardcoded
- Control TOTAL asupra datelor
- Flexibilitate completÄƒ
- Nu mai existÄƒ conflicte label_mode

---

## ðŸ”§ Cum FuncÈ›ioneazÄƒ?

### Fluxul Complet Agnostic

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. FD Simulator - AGNOSTIC Layer                                â”‚
â”‚    fd_simulator_agnostic.py                                      â”‚
â”‚                                                                  â”‚
â”‚    NO hardcoded preprocessing!                                  â”‚
â”‚    NO label_mode decisions!                                     â”‚
â”‚    NO color_mode defaults!                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
             Calls: load_client_data(data_path, batch_size)
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Template - USER CONTROL Layer                                â”‚
â”‚    template_code_agnostic.py                                     â”‚
â”‚                                                                  â”‚
â”‚    def load_client_data(data_path, batch_size):                 â”‚
â”‚        # USER decides:                                           â”‚
â”‚        # - label_mode='int' or 'categorical'                     â”‚
â”‚        # - color_mode='grayscale' or 'rgb'                       â”‚
â”‚        # - image_size=(28, 28) or (224, 224)                     â”‚
â”‚        # - normalization: /255.0 or standard scaler              â”‚
â”‚        # - augmentation: yes or no                               â”‚
â”‚        # - one-hot encoding: manual or automatic                 â”‚
â”‚        #                                                          â”‚
â”‚        # EVERYTHING is controlled by USER!                       â”‚
â”‚                                                                  â”‚
â”‚        train_ds = image_dataset_from_directory(...)              â”‚
â”‚        train_ds = train_ds.map(custom_preprocess)                â”‚
â”‚        return train_ds, test_ds                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                  Returns: (train_ds, test_ds)
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. FD Simulator - Uses Data As-Is                               â”‚
â”‚                                                                  â”‚
â”‚    model.fit(train_ds)  â† NO modifications!                     â”‚
â”‚    model.evaluate(test_ds)  â† Data used directly!               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“ Template Requirements

### FuncÈ›ie OBLIGATORIE: `load_client_data`

```python
def load_client_data(data_path: str, batch_size: int = 32) -> Tuple:
    """
    ÃŽncarcÄƒ È™i preproceseazÄƒ date pentru FL clients.
    
    IMPORTANT:
    - AceastÄƒ funcÈ›ie oferÄƒ CONTROL COMPLET
    - Simulatorul NU va aplica nicio transformare suplimentarÄƒ
    - Datele returnate TREBUIE sÄƒ fie gata pentru antrenare
    
    Args:
        data_path: Path cÄƒtre date (ex: "clean_data")
        batch_size: Dimensiunea batch-ului
        
    Returns:
        (train_ds, test_ds): Datasets complet preprocesate
    """
    # YOUR IMPLEMENTATION HERE
    pass
```

### Exemplu Complet (TensorFlow)

```python
def load_client_data(data_path: str, batch_size: int = 32):
    """Load data for FL simulation with FULL control."""
    from pathlib import Path
    import tensorflow as tf
    
    data_path = Path(data_path)
    train_dir = data_path / "train"
    test_dir = data_path / "test"
    
    # Step 1: Load from directories
    # YOU decide label_mode, color_mode, image_size!
    train_ds = tf.keras.utils.image_dataset_from_directory(
        train_dir,
        image_size=(28, 28),        # âœ… YOUR choice
        batch_size=batch_size,
        color_mode='grayscale',     # âœ… YOUR choice
        label_mode='int',           # âœ… YOUR choice - no double one-hot!
        shuffle=True,
        seed=42
    )
    
    test_ds = tf.keras.utils.image_dataset_from_directory(
        test_dir,
        image_size=(28, 28),
        batch_size=batch_size,
        color_mode='grayscale',
        label_mode='int',
        shuffle=False
    )
    
    # Step 2: Apply YOUR preprocessing
    def my_preprocess(image, label):
        # âœ… YOUR normalization
        image = tf.cast(image, tf.float32) / 255.0
        
        # âœ… YOUR encoding strategy
        label = tf.cast(label, tf.int32)
        label = tf.one_hot(label, 10)  # ONE-HOT only once!
        
        return image, label
    
    train_ds = train_ds.map(my_preprocess, num_parallel_calls=tf.data.AUTOTUNE)
    test_ds = test_ds.map(my_preprocess, num_parallel_calls=tf.data.AUTOTUNE)
    
    # Step 3: Optimization (optional)
    train_ds = train_ds.prefetch(tf.data.AUTOTUNE)
    test_ds = test_ds.prefetch(tf.data.AUTOTUNE)
    
    return train_ds, test_ds
```

### Exemplu Complet (PyTorch)

```python
def load_client_data(data_path: str, batch_size: int = 32):
    """Load data for FL simulation with PyTorch."""
    from pathlib import Path
    from torchvision import datasets, transforms
    from torch.utils.data import DataLoader
    
    data_path = Path(data_path)
    
    # Step 1: Define YOUR transforms
    transform = transforms.Compose([
        transforms.Resize((28, 28)),        # âœ… YOUR size
        transforms.Grayscale(),             # âœ… YOUR color mode
        transforms.ToTensor(),              # âœ… YOUR conversion
        transforms.Normalize((0.5,), (0.5,))  # âœ… YOUR normalization
    ])
    
    # Step 2: Load datasets
    train_dataset = datasets.ImageFolder(
        data_path / "train",
        transform=transform
    )
    
    test_dataset = datasets.ImageFolder(
        data_path / "test",
        transform=transform
    )
    
    # Step 3: Create dataloaders
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=2
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=2
    )
    
    return train_loader, test_loader
```

---

## ðŸŽ¯ Cazuri de Utilizare

### Caz 1: MNIST cu One-Hot Encoding

```python
def load_client_data(data_path: str, batch_size: int = 32):
    train_ds = tf.keras.utils.image_dataset_from_directory(
        Path(data_path) / "train",
        image_size=(28, 28),
        batch_size=batch_size,
        color_mode='grayscale',
        label_mode='int'  # â† Indici Ã®ntregi
    )
    
    test_ds = tf.keras.utils.image_dataset_from_directory(
        Path(data_path) / "test",
        image_size=(28, 28),
        batch_size=batch_size,
        color_mode='grayscale',
        label_mode='int'
    )
    
    def preprocess(image, label):
        image = tf.cast(image, tf.float32) / 255.0
        label = tf.one_hot(label, 10)  # One-hot manual
        return image, label
    
    train_ds = train_ds.map(preprocess).prefetch(tf.data.AUTOTUNE)
    test_ds = test_ds.map(preprocess).prefetch(tf.data.AUTOTUNE)
    
    return train_ds, test_ds
```

**Model compile**:
```python
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',  # â† One-hot labels
    metrics=['accuracy']
)
```

### Caz 2: CIFAR-10 cu Sparse Labels

```python
def load_client_data(data_path: str, batch_size: int = 32):
    train_ds = tf.keras.utils.image_dataset_from_directory(
        Path(data_path) / "train",
        image_size=(32, 32),
        batch_size=batch_size,
        color_mode='rgb',
        label_mode='int'  # â† Keep as integers
    )
    
    test_ds = tf.keras.utils.image_dataset_from_directory(
        Path(data_path) / "test",
        image_size=(32, 32),
        batch_size=batch_size,
        color_mode='rgb',
        label_mode='int'
    )
    
    def preprocess(image, label):
        image = tf.cast(image, tf.float32) / 255.0
        # NO one-hot encoding - keep as integers!
        return image, label
    
    train_ds = train_ds.map(preprocess).prefetch(tf.data.AUTOTUNE)
    test_ds = test_ds.map(preprocess).prefetch(tf.data.AUTOTUNE)
    
    return train_ds, test_ds
```

**Model compile**:
```python
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',  # â† Integer labels
    metrics=['accuracy']
)
```

### Caz 3: ImageNet cu Data Augmentation

```python
def load_client_data(data_path: str, batch_size: int = 32):
    train_ds = tf.keras.utils.image_dataset_from_directory(
        Path(data_path) / "train",
        image_size=(224, 224),
        batch_size=batch_size,
        color_mode='rgb',
        label_mode='categorical'  # â† Automat one-hot pentru multe clase
    )
    
    test_ds = tf.keras.utils.image_dataset_from_directory(
        Path(data_path) / "test",
        image_size=(224, 224),
        batch_size=batch_size,
        color_mode='rgb',
        label_mode='categorical'
    )
    
    # Data augmentation pentru training
    def augment_and_preprocess(image, label):
        # Augmentation
        image = tf.image.random_flip_left_right(image)
        image = tf.image.random_brightness(image, 0.2)
        image = tf.image.random_contrast(image, 0.8, 1.2)
        
        # Normalization (ImageNet stats)
        image = tf.cast(image, tf.float32) / 255.0
        image = (image - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]
        
        return image, label
    
    def preprocess_only(image, label):
        image = tf.cast(image, tf.float32) / 255.0
        image = (image - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]
        return image, label
    
    train_ds = train_ds.map(augment_and_preprocess).prefetch(tf.data.AUTOTUNE)
    test_ds = test_ds.map(preprocess_only).prefetch(tf.data.AUTOTUNE)
    
    return train_ds, test_ds
```

---

## âœ… Avantaje Simulatorul Agnostic

| Aspect | Simulator Opinionated (vechi) | Simulator Agnostic (nou) |
|--------|-------------------------------|---------------------------|
| **Preprocesare** | Hardcoded Ã®n simulator | DefinitÄƒ Ã®n template |
| **label_mode** | Impus de simulator | Controlat de user |
| **color_mode** | Impus de simulator | Controlat de user |
| **Normalization** | Default /255.0 | Custom Ã®n template |
| **Data Augmentation** | Impossible | Posibil Ã®n template |
| **One-Hot Encoding** | Risc de double encoding | Control complet |
| **Flexibilitate** | Low | HIGH |
| **Debugging** | Dificil (logic Ã®n 2 locuri) | UÈ™or (toatÄƒ logica Ã®n template) |

---

## ðŸš¨ Migrare de la Vechiul Simulator

### Ce Trebuie sÄƒ Faci

1. **AdaugÄƒ funcÈ›ia `load_client_data` Ã®n template**
   ```python
   def load_client_data(data_path: str, batch_size: int = 32):
       # Implementare completÄƒ aici
       pass
   ```

2. **MutÄƒtoatÄƒ preprocesarea din mental model la template**
   - Label mode (int vs categorical)
   - Color mode (grayscale vs rgb)
   - Normalization strategy
   - Data augmentation

3. **VerificÄƒ compatibilitatea cu loss function**
   ```python
   # DacÄƒ foloseÈ™ti categorical_crossentropy:
   label_mode='int' + manual one-hot Ã®n preprocess
   
   # DacÄƒ foloseÈ™ti sparse_categorical_crossentropy:
   label_mode='int' + NO one-hot
   ```

4. **TesteazÄƒ local Ã®nainte de deploy**

---

## ðŸ“‹ Checklist Template Agnostic

- [ ] `load_client_data(data_path, batch_size)` implementatÄƒ
- [ ] `label_mode` setat corect (int / categorical)
- [ ] `color_mode` setat corect (grayscale / rgb)
- [ ] Preprocesare definitÄƒ explicit (normalization)
- [ ] One-hot encoding aplicat O SINGURÄ‚ DATÄ‚ (dacÄƒ e necesar)
- [ ] Loss function compatibil cu label format
- [ ] Testat local: `train_ds, test_ds = load_client_data("clean_data", 32)`
- [ ] Verificat shapes: `for imgs, lbls in train_ds.take(1): print(imgs.shape, lbls.shape)`

---

## ðŸŽ“ Best Practices

### 1. DefineÈ™te helper functions Ã®n template

```python
def create_preprocess_function(num_classes: int):
    """Factory for preprocessing functions."""
    def preprocess(image, label):
        image = tf.cast(image, tf.float32) / 255.0
        label = tf.one_hot(label, num_classes)
        return image, label
    return preprocess

def load_client_data(data_path: str, batch_size: int = 32):
    train_ds = ...
    test_ds = ...
    
    preprocess_fn = create_preprocess_function(num_classes=10)
    train_ds = train_ds.map(preprocess_fn)
    test_ds = test_ds.map(preprocess_fn)
    
    return train_ds, test_ds
```

### 2. DocumenteazÄƒ detaliile

```python
def load_client_data(data_path: str, batch_size: int = 32):
    """
    Load MNIST data for FL simulation.
    
    Data format:
    - Images: grayscale 28x28, normalized to [0, 1]
    - Labels: one-hot encoded (10 classes)
    - Batch size: configurable
    
    Preprocessing pipeline:
    1. Load from directory (label_mode='int')
    2. Normalize: /255.0
    3. One-hot encode labels manually
    4. Batch and prefetch
    """
    # Implementation
    pass
```

### 3. ValideazÄƒ output-ul

```python
def load_client_data(data_path: str, batch_size: int = 32):
    train_ds, test_ds = _internal_load(data_path, batch_size)
    
    # Validate shapes
    for images, labels in train_ds.take(1):
        assert images.shape == (batch_size, 28, 28, 1), "Wrong image shape"
        assert labels.shape == (batch_size, 10), "Wrong label shape"
        assert tf.reduce_min(images) >= 0.0, "Images not normalized"
        assert tf.reduce_max(images) <= 1.0, "Images not normalized"
    
    return train_ds, test_ds
```

---

**Versiune**: 3.0 - Fully Agnostic  
**Data**: October 25, 2025  
**Status**: âœ… PRODUCTION READY  
**Breaking Changes**: YES - requires template update
